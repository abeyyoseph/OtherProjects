{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3145ac7-031f-427c-aa46-c49c7b2b96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1631c609-92b1-483c-b8e5-4382b2706138",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8a4e9ab-66aa-438d-b3ce-aa41a2080915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # Root directory contains all subdirectories (e.g., 'good', 'crack', etc.)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Iterate through subdirectories\n",
    "        for subdir in os.listdir(root_dir):\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                # If the subdirectory is 'good', label as 0 (non-anomalous)\n",
    "                label = 0 if subdir == 'good' else 1\n",
    "                for image_name in os.listdir(subdir_path):\n",
    "                    image_path = os.path.join(subdir_path, image_name)\n",
    "                    self.image_paths.append(image_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Open image and convert to RGB\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b466b3b-1ae0-4d7b-a835-dfa961e06fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # 1 input channel (grayscale image)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),  # Batch normalization after convolution\n",
    "            nn.Dropout(0.25),    # Dropout layer to prevent overfitting\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),  # Batch normalization after convolution\n",
    "            nn.Dropout(0.25),    # Dropout layer\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # New deeper layer\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),  # Batch normalization after convolution\n",
    "            nn.Dropout(0.25),    # Dropout layer\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),  # Batch normalization after deconvolution\n",
    "            nn.Dropout(0.25),    # Dropout layer\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),  # Batch normalization after deconvolution\n",
    "            nn.Dropout(0.25),    # Dropout layer\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),  # To normalize output to [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d6c88da-5b7a-49bf-8f76-dff79f534976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert to grayscale\n",
    "    transforms.Resize((512, 512)),  # Resize to a fixed size\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027527a9-65e8-4e9c-a5c1-72b2af4df060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d653ccf5-c254-43d8-a5f3-a53dafc4c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(autoencoder, dataloader, item, num_epochs, device, save_path=\".\"):\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # Move the model to the specified device\n",
    "    autoencoder.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        autoencoder.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)  # Move data to the same device as the model\n",
    "            \n",
    "            # Forward pass\n",
    "            reconstructed = autoencoder(images)\n",
    "            loss = criterion(reconstructed, images)  # Compare reconstructed and original images\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print epoch summary\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_filename = f\"{item}_autoencoder.pth\"\n",
    "    model_path = os.path.join(save_path, model_filename)\n",
    "    torch.save(autoencoder.state_dict(), model_path)\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59d19113-1b83-46d7-83eb-5a482d5f49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder(model, test_loader, device, threshold):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    anomalies = []\n",
    "    false_positives = 0  # Counter for false positives\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  # These are the class labels (good, crack, poke, etc.)\n",
    "            print(labels)\n",
    "            # Get the model's reconstruction of the images\n",
    "            reconstructed = model(images)\n",
    "\n",
    "            # Calculate the reconstruction error (difference between input and output)\n",
    "            reconstruction_error = torch.mean((reconstructed - images) ** 2, dim=[1, 2, 3])\n",
    "\n",
    "            # Identify anomalies based on reconstruction error exceeding the threshold\n",
    "            predicted_anomalies = reconstruction_error > threshold\n",
    "\n",
    "            # Track false positives: if the image is from the \"good\" class and predicted as anomalous\n",
    "            for i, is_anomalous in enumerate(predicted_anomalies):\n",
    "                image_label = labels[i].item()\n",
    "                if is_anomalous.item():\n",
    "                    anomalies.append((image_label, \"Anomaly\"))\n",
    "                    if image_label == 0:  # 0 is assumed to be \"good\"\n",
    "                        false_positives += 1\n",
    "                else:\n",
    "                    anomalies.append((image_label, \"Good\"))\n",
    "\n",
    "            # Flatten the tensors for comparison\n",
    "            predicted_anomalies = predicted_anomalies.view(-1)  # Flatten the anomalies tensor\n",
    "            labels = (labels != 0).view(-1)  # Flatten labels and treat \"good\" as non-anomalous\n",
    "\n",
    "            # Count correct predictions (for anomaly detection, assuming \"good\" = non-anomalous, others = anomalous)\n",
    "            correct += (predicted_anomalies == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    false_positive_rate = false_positives / total if total > 0 else 0  # Avoid division by zero\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b7df2ee-1f9d-48bf-9c71-ab27ec2fe178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: capsule\n",
      "Epoch [1/10], Loss: 0.128091\n",
      "Epoch [2/10], Loss: 0.128075\n",
      "Epoch [3/10], Loss: 0.128120\n",
      "Epoch [4/10], Loss: 0.128095\n",
      "Epoch [5/10], Loss: 0.128174\n",
      "Epoch [6/10], Loss: 0.128117\n",
      "Epoch [7/10], Loss: 0.128091\n",
      "Epoch [8/10], Loss: 0.128197\n",
      "Epoch [9/10], Loss: 0.128156\n",
      "Epoch [10/10], Loss: 0.128107\n",
      "Model saved to: ./capsule_autoencoder.pth\n"
     ]
    }
   ],
   "source": [
    "# Will use the images in the \"train/good\" directory to establish a baseline of features for defect-free images.\n",
    "categories = [\"capsule\", \"screw\", \"cable\", \"transistor\"]\n",
    "threshold = 0.05  # Threshold for anomaly detection\n",
    "\n",
    "# Iterate through the directories of images\n",
    "for item in categories:\n",
    "    item_path = os.path.join(base_dir, item)\n",
    "    train_path = os.path.join(item_path, 'train')\n",
    "    test_path = os.path.join(item_path, 'test')\n",
    "    ground_truth_path = os.path.join(item_path, 'ground_truth')\n",
    "\n",
    "    print(f\"Processing: {item}\")\n",
    "    train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Create your dataset and DataLoader    \n",
    "    model = Autoencoder()\n",
    "    trained_autoencoder = train_autoencoder(model, train_loader, item, epochs, device)    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a5eaab0-e3c8-44ba-bd44-4390d3b35572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1])\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0])\n",
      "tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 1, 1, 1])\n",
      "Test Accuracy: 0.8258\n",
      "False Positive Rate: 0.1742\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(root_dir='Images/capsule/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_autoencoder(model, test_loader, device, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa565a8-5e50-47d7-b753-16ae79a8bef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
