{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51ce3eb1-adee-46b0-a1cc-8be3c06f8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cced94-4fb6-4bde-b3d3-fabd1f66f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names based on the dataset documentation\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
    "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
    "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "network_data = pd.read_csv(\"kddcup.data.corrected\", names=column_names, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c84e58b-3457-4e3e-9824-a568dfbce112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898431 entries, 0 to 4898430\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   duration                     int64  \n",
      " 1   protocol_type                object \n",
      " 2   service                      object \n",
      " 3   flag                         object \n",
      " 4   src_bytes                    int64  \n",
      " 5   dst_bytes                    int64  \n",
      " 6   land                         int64  \n",
      " 7   wrong_fragment               int64  \n",
      " 8   urgent                       int64  \n",
      " 9   hot                          int64  \n",
      " 10  num_failed_logins            int64  \n",
      " 11  logged_in                    int64  \n",
      " 12  num_compromised              int64  \n",
      " 13  root_shell                   int64  \n",
      " 14  su_attempted                 int64  \n",
      " 15  num_root                     int64  \n",
      " 16  num_file_creations           int64  \n",
      " 17  num_shells                   int64  \n",
      " 18  num_access_files             int64  \n",
      " 19  num_outbound_cmds            int64  \n",
      " 20  is_host_login                int64  \n",
      " 21  is_guest_login               int64  \n",
      " 22  count                        int64  \n",
      " 23  srv_count                    int64  \n",
      " 24  serror_rate                  float64\n",
      " 25  srv_serror_rate              float64\n",
      " 26  rerror_rate                  float64\n",
      " 27  srv_rerror_rate              float64\n",
      " 28  same_srv_rate                float64\n",
      " 29  diff_srv_rate                float64\n",
      " 30  srv_diff_host_rate           float64\n",
      " 31  dst_host_count               int64  \n",
      " 32  dst_host_srv_count           int64  \n",
      " 33  dst_host_same_srv_rate       float64\n",
      " 34  dst_host_diff_srv_rate       float64\n",
      " 35  dst_host_same_src_port_rate  float64\n",
      " 36  dst_host_srv_diff_host_rate  float64\n",
      " 37  dst_host_serror_rate         float64\n",
      " 38  dst_host_srv_serror_rate     float64\n",
      " 39  dst_host_rerror_rate         float64\n",
      " 40  dst_host_srv_rerror_rate     float64\n",
      " 41  label                        object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 1.5+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(network_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b407d6bb-dcfc-4357-98ba-ff02b159f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in each column\n",
    "missing_values = network_data.isnull().sum()\n",
    "\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfbec945-d580-434a-af80-b74733fc1f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.',\n",
       "       'smurf.', 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.',\n",
       "       'ipsweep.', 'land.', 'ftp_write.', 'back.', 'imap.', 'satan.',\n",
       "       'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n",
       "       'spy.', 'rootkit.'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all labels\n",
    "network_data[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47760cb3-ddfd-40af-bd9c-4c69b12f919b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       972781\n",
       "protocol_type                  972781\n",
       "service                        972781\n",
       "flag                           972781\n",
       "src_bytes                      972781\n",
       "dst_bytes                      972781\n",
       "land                           972781\n",
       "wrong_fragment                 972781\n",
       "urgent                         972781\n",
       "hot                            972781\n",
       "num_failed_logins              972781\n",
       "logged_in                      972781\n",
       "num_compromised                972781\n",
       "root_shell                     972781\n",
       "su_attempted                   972781\n",
       "num_root                       972781\n",
       "num_file_creations             972781\n",
       "num_shells                     972781\n",
       "num_access_files               972781\n",
       "num_outbound_cmds              972781\n",
       "is_host_login                  972781\n",
       "is_guest_login                 972781\n",
       "count                          972781\n",
       "srv_count                      972781\n",
       "serror_rate                    972781\n",
       "srv_serror_rate                972781\n",
       "rerror_rate                    972781\n",
       "srv_rerror_rate                972781\n",
       "same_srv_rate                  972781\n",
       "diff_srv_rate                  972781\n",
       "srv_diff_host_rate             972781\n",
       "dst_host_count                 972781\n",
       "dst_host_srv_count             972781\n",
       "dst_host_same_srv_rate         972781\n",
       "dst_host_diff_srv_rate         972781\n",
       "dst_host_same_src_port_rate    972781\n",
       "dst_host_srv_diff_host_rate    972781\n",
       "dst_host_serror_rate           972781\n",
       "dst_host_srv_serror_rate       972781\n",
       "dst_host_rerror_rate           972781\n",
       "dst_host_srv_rerror_rate       972781\n",
       "label                          972781\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of data points with a \"normal\" label\n",
    "network_data[network_data[\"label\"] == \"normal.\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdbad3b8-d892-46aa-a5a1-a38bad0debd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data labeled normal for training the VAE\n",
    "normal_data = network_data[network_data[\"label\"] == \"normal.\"].drop(columns=[\"label\"])\n",
    "\n",
    "# One hot encode the categorical features\n",
    "categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "encoded_categories = encoder.fit_transform(normal_data[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a18667e8-50b8-4661-abdf-d56ea70ed8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "numerical_cols = normal_data.drop(columns=categorical_cols).columns\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical_data = scaler.fit_transform(normal_data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca46554-2885-4a99-a4fd-878dab4e428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the encoded and standardized data\n",
    "combined_data = np.hstack([scaled_numerical_data, encoded_categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9722241-4bf2-470e-993c-a9e847abdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train/validation/test data (80/10/10)\n",
    "train_data, temp_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7e8f250-b1b2-4830-8c8f-e41fdf5dc393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE class\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=16, dropout_prob=0.3):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder section\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128), # batch norm\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob), # dropout\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "        )\n",
    "        \n",
    "        # Mean of latent distribution\n",
    "        self.mu_layer = nn.Linear(64, latent_dim)\n",
    "        # Log variance of latent distribution\n",
    "        self.logvar_layer = nn.Linear(64, latent_dim)\n",
    "\n",
    "        # Decoder section\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.BatchNorm1d(64),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()  # Assumes inputs normalized between 0 and 1\n",
    "        )\n",
    "\n",
    "    # Keep the latent space stochastic, preventing the VAE from collapsing into a deterministic autoencoder\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Convert log variance to standard deviation\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        # Random sample from standard normal\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        # Shift and scale eps to match the desired distribution\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode the input data\n",
    "        hidden = self.encoder(x)\n",
    "        mu, logvar = self.mu_layer(hidden), self.logvar_layer(hidden)\n",
    "\n",
    "        assert not torch.isnan(mu).any(), 'NaN detected in mu'\n",
    "        assert not torch.isnan(logvar).any(), 'NaN detected in logvar'\n",
    "        \n",
    "        # Sample latent vector\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # Decode the latent representation\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mu, logvar\n",
    "\n",
    "    def loss_function(self, x, reconstructed_x, mu, logvar):\n",
    "        # Calculate the reconstruction loss (MSE)\n",
    "        reconstruction_loss = F.mse_loss(reconstructed_x, x, reduction='sum')\n",
    "\n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "525d32f7-60e3-4f9e-b83a-078f9c80694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to pytorch tensors\n",
    "train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "val_tensor = torch.tensor(val_data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85f0645f-ee90-4153-b5fc-002355aa6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 0.001\n",
    "decay = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "input_dimensions = train_data.shape[1]\n",
    "latent_dimensions = 32\n",
    "vae = VAE(input_dimensions, latent_dimensions).to(device)\n",
    "optimizer = optim.AdamW(vae.parameters(), lr=learning_rate, weight_decay=decay)\n",
    "# Reduce LR in half if val loss doesn't decrease for 4 epochs\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cdc54a1-fdb0-4fc6-a5d2-da78d78654f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(TensorDataset(train_tensor), batch_size=batch_size)\n",
    "val_loader = DataLoader(TensorDataset(val_tensor), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ce558-87e4-4518-b976-1b5e709d8ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Loss: 1116.4185 | Val Loss: 1420.8759\n",
      "New best model saved.\n",
      "Epoch [2/50] - Train Loss: 1043.4382 | Val Loss: 1390.8957\n",
      "New best model saved.\n",
      "Epoch [3/50] - Train Loss: 1026.8123 | Val Loss: 1518.1093\n",
      "Epoch [4/50] - Train Loss: 1023.6392 | Val Loss: 1390.9208\n",
      "Epoch [5/50] - Train Loss: 1022.4049 | Val Loss: 1412.2557\n",
      "Epoch [6/50] - Train Loss: 1021.4028 | Val Loss: 1394.6940\n",
      "Epoch [7/50] - Train Loss: 1019.9279 | Val Loss: 1385.5111\n",
      "New best model saved.\n",
      "Epoch [8/50] - Train Loss: 1019.3714 | Val Loss: 1387.3758\n",
      "Epoch [9/50] - Train Loss: 1018.8950 | Val Loss: 1388.8670\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"best_vae_model.pth\"\n",
    "best_val_loss = float(\"inf\")\n",
    "criterion = vae.loss_function\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x = batch[0].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Get the decoded latent representation, the mean and log variance\n",
    "        reconstructed_x, mu, logvar = vae(x)\n",
    "\n",
    "        loss = criterion(x, reconstructed_x, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    vae.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch[0].to(device)\n",
    "            reconstructed_x, mu, logvar = vae(x)\n",
    "\n",
    "            loss = criterion(x, reconstructed_x, mu, logvar)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(\"New best model saved.\")\n",
    "        torch.save(vae.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fdea4-cb7b-4446-8f5e-9103988333f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfd426-05a5-4fc3-9ec7-5a3eede02071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
