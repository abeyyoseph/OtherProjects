{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40d047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a220ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify the directory containing the text files\n",
    "directory = 'datasets/HandGestureDataset/train/labels'\n",
    "\n",
    "# Initialize a Counter to store the frequencies of the first numbers\n",
    "first_numbers = Counter()\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):  # Ensure it's a text file\n",
    "        with open(os.path.join(directory, filename), 'r') as file:\n",
    "            first_line = file.readline()  # Read the first line of the file\n",
    "            first_number = int(first_line.split()[0])  # Extract the first number (as string)\n",
    "            first_numbers[first_number+1] += 1  # Increment the count of this number in the Counter\n",
    "\n",
    "# Plotting\n",
    "# Extract the numbers and their frequencies\n",
    "numbers = list(first_numbers.keys())\n",
    "frequencies = list(first_numbers.values())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.bar(numbers, frequencies, color='blue')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Label Distribution in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7723f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d125f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.6 🚀 Python-3.8.10 torch-2.3.0+cu121 CPU (Intel Core(TM) i7-9850H 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/runs/detect/train13/weights/best.pt, data=/home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/datasets/HandGestureDataset/data.yaml, epochs=20, time=None, patience=100, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 70/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/datasets/HandGestureDataset/train/labels.cache... 587 images, 0 backgrounds, 0 corrupt: 100%|██████████| 587/587 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/datasets/HandGestureDataset/valid/labels.cache... 167 images, 0 backgrounds, 0 corrupt: 100%|██████████| 167/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      2.218      2.602      2.061         30        416: 100%|██████████| 19/19 [01:06<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.264      0.284      0.184     0.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G       1.52      1.866       1.66         30        416: 100%|██████████| 19/19 [01:13<00:00,  3.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.234      0.338      0.245      0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G       1.26      1.683      1.486         29        416: 100%|██████████| 19/19 [01:15<00:00,  3.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.401      0.575      0.465      0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      1.156      1.559      1.406         22        416: 100%|██████████| 19/19 [01:18<00:00,  4.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.563      0.618      0.679      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      1.141      1.491      1.372         23        416: 100%|██████████| 19/19 [01:43<00:00,  5.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.678      0.652      0.767      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      1.136      1.498      1.359         25        416: 100%|██████████| 19/19 [01:17<00:00,  4.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:13<00:00,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.816       0.67      0.817      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.105      1.463      1.334         29        416: 100%|██████████| 19/19 [01:18<00:00,  4.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09<00:00,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.611      0.738      0.747      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.092      1.425      1.334         22        416: 100%|██████████| 19/19 [01:09<00:00,  3.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.766      0.708      0.795      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      1.058      1.365      1.298         28        416: 100%|██████████| 19/19 [01:07<00:00,  3.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167        0.8       0.72      0.823      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.028      1.344      1.282         22        416: 100%|██████████| 19/19 [01:07<00:00,  3.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.773      0.769      0.836      0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      0.796      1.028      1.147         11        416: 100%|██████████| 19/19 [01:06<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.735      0.713      0.783       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G     0.7511     0.8783       1.11         11        416: 100%|██████████| 19/19 [01:12<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.724      0.743      0.799      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G     0.7142     0.8229      1.087         11        416: 100%|██████████| 19/19 [01:07<00:00,  3.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.767      0.788      0.841      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G     0.7241     0.7994      1.087         11        416: 100%|██████████| 19/19 [01:05<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.746      0.789      0.816      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G     0.6858      0.737      1.055         11        416: 100%|██████████| 19/19 [01:04<00:00,  3.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.801       0.76      0.842      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G     0.6697     0.7224      1.039         11        416: 100%|██████████| 19/19 [01:05<00:00,  3.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.824      0.771      0.852      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      0.662     0.7012      1.036         11        416: 100%|██████████| 19/19 [01:05<00:00,  3.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.783      0.799      0.859      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G     0.6593     0.6939      1.037         11        416: 100%|██████████| 19/19 [01:07<00:00,  3.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.813      0.807      0.861      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G     0.6439     0.6267      1.033         11        416: 100%|██████████| 19/19 [01:06<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.813      0.777      0.858      0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G     0.6575     0.6595      1.058         11        416: 100%|██████████| 19/19 [01:06<00:00,  3.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:10<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.834       0.79      0.867        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.451 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.6 🚀 Python-3.8.10 torch-2.3.0+cu121 CPU (Intel Core(TM) i7-9850H 2.60GHz)\n",
      "Model summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:08<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.824      0.785      0.867        0.7\n",
      "                  five        167         77      0.835      0.791       0.85      0.647\n",
      "                  four        167         21      0.751      0.857        0.9      0.731\n",
      "                   one        167         19      0.821      0.842      0.863      0.706\n",
      "                 three        167         27      0.857      0.667      0.844      0.712\n",
      "                   two        167         23      0.855      0.768      0.878      0.701\n",
      "Speed: 0.6ms preprocess, 43.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=\"/home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/datasets/HandGestureDataset/data.yaml\",\n",
    "                     epochs=20, batch=32, imgsz=416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6156c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.6 🚀 Python-3.8.10 torch-2.3.0+cu121 CPU (Intel Core(TM) i7-9850H 2.60GHz)\n",
      "Model summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/datasets/HandGestureDataset/valid/labels.cache... 167 images, 0 backgrounds, 0 corrupt: 100%|██████████| 167/167 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        167        167      0.824      0.785      0.867        0.7\n",
      "                  five        167         77      0.835      0.791       0.85      0.647\n",
      "                  four        167         21      0.751      0.857        0.9      0.731\n",
      "                   one        167         19      0.821      0.842      0.863      0.706\n",
      "                 three        167         27      0.857      0.667      0.844      0.712\n",
      "                   two        167         23      0.855      0.768      0.878      0.701\n",
      "Speed: 1.2ms preprocess, 48.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the best performing model from the training\n",
    "model = YOLO('/home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/runs/detect/train/weights/best.pt')\n",
    "\n",
    "# Run validation on a set specified as 'val' argument\n",
    "metrics = model.val(data='/home/abey/Desktop/Repos/Data_Analysis_Scripts/YOLODetection/datasets/HandGestureDataset/data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283d52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
