{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36088d94-8969-4556-962a-9d2a3fe90edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8044ca7b-fe73-453a-b230-784dc281d8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/10/2004</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  3/10/2004  18:00:00     2.6       1360.0     150.0      11.9   \n",
       "1  3/10/2004  19:00:00     2.0       1292.0     112.0       9.4   \n",
       "2  3/10/2004  20:00:00     2.2       1402.0      88.0       9.0   \n",
       "3  3/10/2004  21:00:00     2.2       1376.0      80.0       9.2   \n",
       "4  3/10/2004  22:00:00     1.6       1272.0      51.0       6.5   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0         1046.0    166.0        1056.0    113.0        1692.0       1268.0   \n",
       "1          955.0    103.0        1174.0     92.0        1559.0        972.0   \n",
       "2          939.0    131.0        1140.0    114.0        1555.0       1074.0   \n",
       "3          948.0    172.0        1092.0    122.0        1584.0       1203.0   \n",
       "4          836.0    131.0        1205.0    116.0        1490.0       1110.0   \n",
       "\n",
       "      T    RH      AH  Unnamed: 15  Unnamed: 16  \n",
       "0  13.6  48.9  0.7578          NaN          NaN  \n",
       "1  13.3  47.7  0.7255          NaN          NaN  \n",
       "2  11.9  54.0  0.7502          NaN          NaN  \n",
       "3  11.0  60.0  0.7867          NaN          NaN  \n",
       "4  11.2  59.6  0.7888          NaN          NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"AirQualityUCI.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "355aaefa-71d4-4770-b7d9-d2083bb5d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9471 entries, 0 to 9470\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Measurement_Date                        9357 non-null   object \n",
      " 1   Measurement_Time                        9357 non-null   object \n",
      " 2   Carbon_Monoxide_Concentration           9357 non-null   float64\n",
      " 3   CO_Sensor_Measurement                   9357 non-null   float64\n",
      " 4   Non_Methane_Hydrocarbons_Concentration  9357 non-null   float64\n",
      " 5   Benzene_Concentration                   9357 non-null   float64\n",
      " 6   NMHC_Sensor_Measurement                 9357 non-null   float64\n",
      " 7   Nitrogen_Oxides_Concentration           9357 non-null   float64\n",
      " 8   NOx_Sensor_Measurement                  9357 non-null   float64\n",
      " 9   Nitrogen_Dioxide_Concentration          9357 non-null   float64\n",
      " 10  PT08.S4(NO2)                            9357 non-null   float64\n",
      " 11  PT08.S5(O3)                             9357 non-null   float64\n",
      " 12  Temperature_Celsius                     9357 non-null   float64\n",
      " 13  Relative_Humidity                       9357 non-null   float64\n",
      " 14  Absolute_Humidity                       9357 non-null   float64\n",
      " 15  Unnamed: 15                             0 non-null      float64\n",
      " 16  Unnamed: 16                             0 non-null      float64\n",
      "dtypes: float64(15), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns to be more descriptive\n",
    "data.rename(columns={\n",
    "    'Date': 'Measurement_Date',\n",
    "    'Time': 'Measurement_Time',\n",
    "    'CO(GT)': 'Carbon_Monoxide_Concentration',\n",
    "    'PT08.S1(CO)': 'CO_Sensor_Measurement',\n",
    "    'NMHC(GT)': 'Non_Methane_Hydrocarbons_Concentration',\n",
    "    'C6H6(GT)': 'Benzene_Concentration',\n",
    "    'PT08.S2(NMHC)': 'NMHC_Sensor_Measurement',\n",
    "    'NOx(GT)': 'Nitrogen_Oxides_Concentration',\n",
    "    'PT08.S3(NOx)': 'NOx_Sensor_Measurement',\n",
    "    'NO2(GT)': 'Nitrogen_Dioxide_Concentration',\n",
    "    'T': 'Temperature_Celsius',\n",
    "    'RH': 'Relative_Humidity',\n",
    "    'AH': 'Absolute_Humidity'\n",
    "}, inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95db4821-91d7-4a91-a45b-19aab11cb88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9357 entries, 0 to 9356\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Measurement_Date                        9357 non-null   object \n",
      " 1   Measurement_Time                        9357 non-null   object \n",
      " 2   Carbon_Monoxide_Concentration           9357 non-null   float64\n",
      " 3   CO_Sensor_Measurement                   9357 non-null   float64\n",
      " 4   Non_Methane_Hydrocarbons_Concentration  9357 non-null   float64\n",
      " 5   Benzene_Concentration                   9357 non-null   float64\n",
      " 6   NMHC_Sensor_Measurement                 9357 non-null   float64\n",
      " 7   Nitrogen_Oxides_Concentration           9357 non-null   float64\n",
      " 8   NOx_Sensor_Measurement                  9357 non-null   float64\n",
      " 9   Nitrogen_Dioxide_Concentration          9357 non-null   float64\n",
      " 10  PT08.S4(NO2)                            9357 non-null   float64\n",
      " 11  PT08.S5(O3)                             9357 non-null   float64\n",
      " 12  Temperature_Celsius                     9357 non-null   float64\n",
      " 13  Relative_Humidity                       9357 non-null   float64\n",
      " 14  Absolute_Humidity                       9357 non-null   float64\n",
      "dtypes: float64(13), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove empty last two columns\n",
    "data.drop(data.columns[15:17], axis=1, inplace=True)\n",
    "\n",
    "# After visual inspection, it looks like there are only 9358 entries in the csv file. Not sure why data.info() is registering 9471 \n",
    "# data entries? Because of this, I will only \"keep\" the 9358 rows.\n",
    "data = data[:9357]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "150bd256-c55f-4fbb-8b08-e5d9e2e49fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9223/170350023.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  numerical_data.fillna(numerical_data.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Isolate the numerical data columns\n",
    "numerical_data = data.iloc[:, 2:14]\n",
    "\n",
    "# The dataset notes that some measurements may be recorded as -200, indicating missing or invalid data points. I will remove \n",
    "# any -200 values and replace them with the mean value in the column.\n",
    "numerical_data.replace(-200, pd.NA, inplace=True)\n",
    "\n",
    "# Replace NaN values with the median of each column\n",
    "numerical_data.fillna(numerical_data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3718489-d77a-483c-8d45-9960b6adfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.2):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.model_type = \"GRU\"  # Model type string\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # The GRU layer processes input sequences and produces outputs and hidden states for each time step.\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        # A fully connected (linear) layer that maps the output of the GRU to the desired output size.\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)  # initialize hidden state\n",
    "        out, _ = self.gru(x, h0)  # GRU layer\n",
    "        out = self.fc(out[:, -1, :])  # Take only the last time step's output\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45023578-324c-42c5-9057-8476075c4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.0):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Fully connected layer to map from hidden_size to output_size (3)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the LSTM layer\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Take the last time step output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dcb4cb5-6484-4ae0-8f0b-14529077b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The time series data that will be predicted is the Nitrogen Dioxide Concentration, Carbon_Monoxide_Concentration, and Temperature_Celsius\n",
    "time_series_data = data[['Nitrogen_Dioxide_Concentration', 'Carbon_Monoxide_Concentration', 'Temperature_Celsius']].to_numpy()\n",
    "\n",
    "# Scale the data using the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "time_series_data = scaler.fit_transform(time_series_data)\n",
    "\n",
    "# Create the input sequences and targets. The target will be the 13th value after a sequence of 12.\n",
    "sequence_length = 12  \n",
    "X, y = [], []\n",
    "for i in range(len(time_series_data) - sequence_length):\n",
    "    X.append(time_series_data[i:i + sequence_length])\n",
    "    y.append(time_series_data[i + sequence_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders for training, validation, and testing\n",
    "dataset = TensorDataset(X, y)\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6eb10a81-98de-4785-b135-de5fc5f4f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining to train with: GRUModel, hidden size: 4, num layers: 1, batch size: 8\n",
      "Best model: GRUModel saved at epoch 1 with validation loss: 0.0194, hidden size: 4, num layers: 1, batch size: 8\n",
      "Best model: GRUModel saved at epoch 6 with validation loss: 0.0191, hidden size: 4, num layers: 1, batch size: 8\n",
      "Best model: GRUModel saved at epoch 22 with validation loss: 0.0191, hidden size: 4, num layers: 1, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 1, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 2, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 2, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 3, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 3, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 1, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 1, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 2, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 2, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 3, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 3, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 1, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 1, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 2, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 2, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 4, num layers: 3, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 4, num layers: 3, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 1, batch size: 8\n",
      "Best model: GRUModel saved at epoch 5 with validation loss: 0.0191, hidden size: 8, num layers: 1, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 1, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 2, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 2, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 3, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 3, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 1, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 1, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 2, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 2, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 3, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 3, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 1, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 1, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 2, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 2, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 8, num layers: 3, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 8, num layers: 3, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 1, batch size: 8\n",
      "Best model: GRUModel saved at epoch 15 with validation loss: 0.0189, hidden size: 16, num layers: 1, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 1, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 2, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 2, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 3, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 3, batch size: 8\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 1, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 1, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 2, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 2, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 3, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 3, batch size: 16\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 1, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 1, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 2, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 2, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: GRUModel, hidden size: 16, num layers: 3, batch size: 32\n",
      "Early stopping at epoch 52\n",
      "Begining to train with: LSTMModel, hidden size: 16, num layers: 3, batch size: 32\n",
      "Early stopping at epoch 52\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 3  # Each time step has three input features\n",
    "hidden_size = [4, 8, 16]  # Number of LSTM/GRU hidden units\n",
    "output_size = 3  # Predicting three values\n",
    "num_layers = [1, 2, 3] # Number of layers in the LSTM/GRU\n",
    "learning_rate = 0.01\n",
    "num_epochs = 75\n",
    "dropout = 0.2\n",
    "weight_decay = 0.01  # L2 regularization strength\n",
    "batch_size = [8, 16, 32]\n",
    "\n",
    "# Set up early stopping\n",
    "patience = 5  # Number of epochs with no improvement to wait before stopping\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Iterate through the hyperparameter space\n",
    "for hidden in hidden_size:\n",
    "    for batch in batch_size:\n",
    "        for layer in num_layers:\n",
    "            \n",
    "            # Create data loaders for each subset\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch)\n",
    "            \n",
    "            # Instantiate models\n",
    "            gru_model = GRUModel(input_size, hidden, output_size, layer, dropout)\n",
    "            lstm_model = LSTMModel(input_size, hidden, output_size, layer, dropout)\n",
    "            models = [gru_model, lstm_model]\n",
    "            criterion = nn.MSELoss()\n",
    "                       \n",
    "            for model in models:\n",
    "                print(f'Begining to train with: {model.__class__.__name__}, 'f'hidden size: {hidden}, num layers: {layer}, batch size: {batch}')\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "                \n",
    "                # Instantiate the scheduler (reduce LR when validation loss has stopped improving)\n",
    "                scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=False)\n",
    "\n",
    "                epochs_since_improvement = 0\n",
    "                \n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()  # Ensure the model is in training mode\n",
    "                    for X_batch, y_batch in train_loader:\n",
    "                        X_batch = X_batch.view(-1, sequence_length, input_size)\n",
    "                        outputs = model(X_batch)\n",
    "                        y_batch = y_batch.view(-1, output_size)\n",
    "                        \n",
    "                        loss = criterion(outputs, y_batch)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                    # Validation step\n",
    "                    model.eval()  # Switch to evaluation mode\n",
    "                    val_loss = 0.0\n",
    "                    with torch.no_grad():\n",
    "                        for X_batch, y_batch in val_loader:\n",
    "                            X_batch = X_batch.view(-1, sequence_length, input_size)\n",
    "                            val_outputs = model(X_batch)\n",
    "                            y_batch = y_batch.view(-1, output_size)\n",
    "                            val_loss += criterion(val_outputs, y_batch).item()\n",
    "\n",
    "                    # Average the validation loss over batches\n",
    "                    val_loss /= len(val_loader)  \n",
    "\n",
    "                    # Step the scheduler based on the validation loss\n",
    "                    scheduler.step(val_loss)\n",
    "                    \n",
    "                    # Check if the validation loss has improved\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        epochs_since_improvement = 0\n",
    "                        model_path = f'best_model_{model.__class__.__name__}_hidden{hidden}_layers{layer}_batch{batch}.pth'\n",
    "                        torch.save(model.state_dict(), model_path)\n",
    "                        print(f'Best model: {model.__class__.__name__} saved at epoch {epoch + 1} with validation loss: {val_loss:.4f}, '\n",
    "                              f'hidden size: {hidden}, num layers: {layer}, batch size: {batch}')\n",
    "                    else:\n",
    "                        epochs_since_improvement += 1\n",
    "\n",
    "                    # If 5 epochs have passed without improvement after the first 50 epochs, the training stops for this model with the\n",
    "                    # current hyperparameters\n",
    "                    if epoch > 50 and epochs_since_improvement >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5661af04-3e5b-49ce-92b3-7a3daacb1631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 0.0219\n",
      "Mean Absolute Error (MAE): 0.0744\n",
      "R-squared (R^2): 0.6811\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data with the best performing model from training/validation\n",
    "model = GRUModel(input_size=3, hidden_size=16, output_size=3, num_layers=1, dropout=0.2)\n",
    "model.load_state_dict(torch.load('best_model_GRUModel_hidden16_layers1_batch8.pth', weights_only=True))\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_outputs = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.view(-1, sequence_length, input_size)\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        y_batch = y_batch.view(-1, output_size)  # Adjust to the correct shape\n",
    "\n",
    "        all_outputs.append(outputs.numpy())\n",
    "        all_targets.append(y_batch.view(-1, output_size).numpy())\n",
    "        \n",
    "        # Accumulate the batch loss\n",
    "        test_loss += criterion(outputs, y_batch).item()\n",
    "        \n",
    "test_loss /= len(test_loader)\n",
    "# Concatenate all outputs and targets\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "# Compute additional metrics\n",
    "mae = mean_absolute_error(all_targets, all_outputs)\n",
    "r2 = r2_score(all_targets, all_outputs)\n",
    "\n",
    "print(f'Test Loss (MSE): {test_loss:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'R-squared (R^2): {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab3aca97-de62-4f1c-bd3f-7d10ca00e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338.0\n",
      "11.8\n",
      "46.5\n"
     ]
    }
   ],
   "source": [
    "print(numerical_data['Nitrogen_Dioxide_Concentration'].max() - numerical_data['Nitrogen_Dioxide_Concentration'].min())\n",
    "print(numerical_data['Carbon_Monoxide_Concentration'].max() - numerical_data['Carbon_Monoxide_Concentration'].min())\n",
    "print(numerical_data['Temperature_Celsius'].max() - numerical_data['Temperature_Celsius'].min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
